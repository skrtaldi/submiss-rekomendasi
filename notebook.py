# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O5U8MY24GFDeMwEGsrOuYRLLazG3nSBe

# Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re
import gdown

"""# Data Understanding"""

FILE_ID = '11mhE9oRfJ_qUlF18vNCyoc8G9zTJZtwz'
url = f"https://drive.google.com/uc?id={FILE_ID}"

output = 'anime.csv'
gdown.download(url, output, quiet=False)

FILE_ID = '1sH7BIzX0GLaZozq5T6etjtLlpk1WFDBJ'
url = f"https://drive.google.com/uc?id={FILE_ID}"
output = 'rating.csv'
gdown.download(url, output, quiet=False)

anime = pd.read_csv('anime.csv')
anime

"""Dataset pada anime.csv terdiri atas 12294 entri dan 7 kolom yaitu, anime_id, name, genre, type, episodes, rating, dan members:
- anime_id : merupakan id unik untuk setiap judul anime yang dimiliki oleh myanimelist.net
- name : merupakan nama atau judul lengkap dari setiap anime
- genre : merupakan genre dari anime tersebut, genre bisa lebih dari satu dan dipisahkan oleh koma.
- type : merupakan tipe dari anime seperti TV, Movie, OVA, Special, Music.
- episodes : merupakan jumlah episode dari anime, data unknown menandakan bahwa anime tersebut masing on-going.
- rating : merupakan rata-rata rating yang diberikan oleh pengguna
- members : merupakan total pengguna yang menandai anime sebagai sudah ditonton, sedang ditonton, atau akan ditonton.
"""

anime.isnull().sum()

"""Pada dataset anime terdapat beberapa kolom yang memiliki missing values yaitu:
- genre dengan 62 missing values
- type dengan 25 missing values
- rating dengan 230 missing values
Sedangkan untuk kolom anime_id, name, episodes dan members memiliki 0 missing values.

"""

rating = pd.read_csv('rating.csv')
rating

"""Dataset pada rating.csv terdiri atas 7813737 entri dan 3 kolom yaitu, user_id, anime_id dan rating:
- user_id : merupakan id pengguna yang dibuat secara acak dan tidak dapat teridentifikasi.
- anime_id : merupakan id dari anime yang diberikan rating oleh pengguna.
- rating : merupakan nilai rating yang diberikan user dari 1 sampai dengan 10. Data -1 menandakan bahwa user menonton tapi tidak memberikan rating
"""

rating.isnull().sum()

"""Pada dataset rating tidak memiliki missing values untuk setiap kolomnya"""

print('Jumlah data rating oleh user: ', len(rating.user_id.unique()))
print('Jumlah rating untuk anime: ', len(rating.anime_id.unique()))

"""Berdasarkan kode diatas diketahui bahwa:
- Jumlah keseluruhan data rating yang diberikan oleh user adalah 73515
- Jumlah rating untuk anime 11200

# Exploratory Data Analysis

## Anime
"""

anime.info()

"""Dataset anime csv memiliki:
- 3 kolom numerikal yaitu, rating dan members dan anime_id
- 4 kolom kategorikal yaitu, name, genre, type, dan episodes

### Distribusi Tipe Anime
"""

print('Jumlah data anime: ', len(anime.anime_id.unique()))
print('Tipe anime: ', anime.type.unique())

"""Jumlah data anime dalam dataset ini adalah 12294 dan memiliki 6 tipe yaitu:
- Movie
- TV
- OVA
- Special
- Music
- ONA
Ada beberapa juga yang memiliki genre nan
"""

sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)

sns.countplot(x='type', data=anime, palette='Set2')
plt.title('Distribusi Type anime')
plt.xlabel('Tipe anime')
plt.ylabel('Jumlah')
plt.show()

"""Hasil visualisasi dari distribusi tipe anime tersebut dapat diketahui bahwa:
- TV memiliki total lebih dari 3500 anime
- Movie memiliki total lebih dari 2000 anime
- OVA memiliki total lebih dari 3000 anime
- Special memiliki total lebih dari 1500 anime
- Music memiliki total kurang dari 500 anime
- ONA memiliki total lebih dari 500 anime

### Genre Anime
"""

print('Jumlah genre anime: ', len(anime.genre.unique()))
print('Daftar Genre anime: ', anime.genre.unique())

"""Total jumlah genre anime dalam dataset tersebut adalah 3265 genre akan tetapi terdapat banyak anime yang memiliki genre lebih dari satu dan dipisahkan dengan koma

### Members Anime
"""

max_members = anime['members'].max()
min_members = anime['members'].min()

print('Jumlah member anime terbanyak:', max_members)
print('Jumlah member anime tersedikit:', min_members)

"""Terdapat anime dengan member terbanyak sejumlah 1013917 dan anime dengan member paling sedikit adalah berjumlah 5

## Rating
"""

rating.head()

print('Jumlah Seluruh rating: ', len(rating.rating.unique()))
print('Nilai Rating: ', rating.rating.unique())

"""Nilai dari rating seharusnya adalah antara 1 sampai dengan 10. Akan tetapi, terdapat beberapa anime yang memiliki nilai rating -1. Hal ini menandakan bahwa anime tersebut tidak diberikan rating oleh pengguna"""

print('Jumlah Seluruh User: ', len(rating.user_id.unique()))
print('Jumlah Seluruh Anime: ', len(rating.anime_id.unique()))
print('Jumlah Seluruh data rating: ', len(rating))

"""Jumlah keseluruhan pengguna adalah 73515, sedangkan keseluruhan anime adalah 11200, dan data rating sejumlah 7813737

# Data Preparation

## Menggabungkan Keseluruhan Data
"""

data = pd.merge(rating, anime, on='anime_id', how='left')
data

"""Dataset rating dan anime disatukan menjadi sebuah dataframe data menggunakan merge dari library pandas. Data tersebut memiliki 7813737 entri dan 9 kolom hasil penggabungan dataset

## Menggabungkan Data Rating dengan Nama dan Genre Anime
"""

genre_anime = pd.merge(rating, anime[['anime_id', 'name', 'genre']], on='anime_id', how='left')
genre_anime

"""Dataset rating digabungkan dengan kolom name dan genre pada dataset anime dan mengambil kolom name kemudian digabungkan berdasarkan anime_id. Sehingga menghasilkan dataframe dengan 7813737 entri dan 5 kolom

# Data Preparation Content Based
"""

genre_anime.describe()

"""Berdasarkan statistik deskriptif dari dataframe genre_anime. Dapat diketahui bahwa, dalam fitur rating terdapat nilai minimum -1,  dan harus dihapus

## Mengatasi nilai Rating -1
"""

before = len(genre_anime)
genre_anime = genre_anime[genre_anime['rating'] != -1]
after = len(genre_anime)
print(f"{before - after} baris dengan rating -1 telah dihapus.")

"""Dari kode diatas diketahui bahwa terdapat 1476496 baris kolom rating yang bernilai -1"""

print(f"{before - after} baris dengan rating -1 telah dihapus.")
print('Jumlah Seluruh rating: ', len(genre_anime.rating.unique()))
print('Nilai Rating: ', genre_anime.rating.unique())
print('Jumlah Seluruh Data: ', after)

"""Dari kode diatas diketahui bahwa:
- Jumlah keseluruhan rating 10
- Nilai Rating : 10, 9, 8, 7, 6, 5, 4, 3, 2, 1.
- JUmlah keseluruhan data setelah dilakukan pembersihan: 6337241

## Mengatasi Missing Values
"""

genre_anime.isnull().sum()

"""Berdasarkan output diatas, dataframe genre_anime memiliki 2 missing values yaitu:
- name : 2 missing values
- genre : 90 missing values
"""

genre_anime = genre_anime.dropna()
genre_anime.isnull().sum()

"""Setelah dilakukan cleaning data, semua fitur dalam dataframe genre_anime memiliki 0 missing values

## Menangani koma dalam fitur genre
"""

genre_anime.head()

genre_anime['genre'] = genre_anime['genre'].str.replace(', ', ' ')

genre_anime.head()

"""Kolom genre berisi beberapa genre yang digabung dalam satu string dan dipisahkan dengan koma. Maka perlu dilakukan cleaning dengan me-replace tanda koma dengan spasi menggunakan
genre_anime['genre'] = genre_anime['genre'].str.replace(', ', ' ')

## Menangani String Unik pada kolom name
"""

genre_anime['name'] = genre_anime['name'].str.replace(r'[^a-zA-Z0-9\s]', '', regex=True)  # hanya huruf, angka, dan spasi
genre_anime['name'] = genre_anime['name'].str.replace(r'\s+', ' ', regex=True)      # hilangkan spasi ganda
genre_anime['name'] = genre_anime['name'].str.strip()                               # hapus spasi di awal/akhir

"""Langkah ini dilakukan untuk menghapus string unik atau spasi berlebih pada kolom name. Beberapa langkah yang dilakukan adalah:
- Menghapus karakter seperti !,? atau tanda berlebihan
- Menghapus spasi berlebih diawal dan diakhir string.

## Menangani Duplikasi data
"""

genre_fix = genre_anime
genre_fix.sort_values('anime_id')

genre_fix = genre_fix.drop_duplicates('anime_id')
genre_fix

"""Tujuan dilakukan proses ini adalah untuk menghindari dupliaksi output rekomendasi yang sama dan mempersiapkan data agar seragam untuk model berbasis teks atau pencocokan nama

## Membuat Dataframe untuk model Content-Based
"""

anime_id = genre_fix['anime_id'].tolist()
anime_name = genre_fix['name'].tolist()
anime_genre = genre_fix['genre'].tolist()

print(len(anime_id))
print(len(anime_name))
print(len(anime_genre))

"""Langkah ini dilakukan untuk mengubah fitur anime_id, name dan genre kedalam list. Setiap list memiliki jumlah data yang sama yaitu 9894 data"""

preparation = pd.DataFrame({
    'id': anime_id,
    'name': anime_name,
    'genre': anime_genre
})
preparation

"""Kemudian menyiapkan dataframe preparation yang diisi dengan list yang sebelumnya sudah dibuat. Dataframe berisi kolom:
- id : berisi list anime_id
- anime : berisi list anime_name
- genre : berisi list anime_genre

# Data Preparation Collaborative
"""

data_rating = rating
rating.head()

"""berdasarkan dataframe data_rating diketahui bahwa pada dataset rating terdapat rating -1

## Encode user_id
"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = data_rating['user_id'].unique().tolist()
print('list user_id: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded user_id : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke user_id: ', user_encoded_to_user)

"""Langkah-langkah yang dilakukan antara lain:
- Membuat daftar unik user_id, dengan mengambil seluruh nilai unik dari kolom user_id dan menyusunnya dalam bentuk list. Hal ini dilakukan untuk memastikan tidak ada duplikasi saat melakukan mapping
- Membuat Dictionary user_to_user_encoded yang memetakan setiap user_id ke angka unik yang dimulai dari 0
-Membuat Reverse Mapping untuk mengembalikan angka hasil encoding ke  user_id aslinya.

## Encode anime_id
"""

anime_ids = data_rating['anime_id'].unique().tolist()
anime_to_anime_encoded = {x: i for i, x in enumerate(anime_ids)}
anime_encoded_to_anime = {i: x for i, x in enumerate(anime_ids)}

"""## Mapping dan Encoding"""

# Mapping user_id ke dataframe user
data_rating['user'] = data_rating['user_id'].map(user_to_user_encoded)

# Mapping anime_id ke dataframe anime
data_rating['anime'] = data_rating['anime_id'].map(anime_to_anime_encoded)

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)

# Mendapatkan jumlah resto
num_anime = len(anime_encoded_to_anime)
print(num_anime)

# Mengubah rating menjadi nilai float
data_rating['rating'] = data_rating['rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(data_rating['rating'])

# Nilai maksimal rating
max_rating = max(data_rating['rating'])

print('Number of User: {}, Number of Resto: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_anime, min_rating, max_rating
))

"""Langkah-langkah yang dilakukan antara lain:
-  Mengambil nilai unik dari anime_id dan disimpankedalam bentuk list untuk memastikan tidak ada duplikasi.
- Membuat dictionary untuk mapping. Dictionary anime_to_anime_encoded digunakan untuk mengubah anime_id menjadi angka dari 0 hingga jumlah anime unik. Dictionary anime_encoded_to_anime berfungsi sebagai reverse mapping yaitu untuk mengembalikan angka ke anime_id.

## Menangani Rating -1
"""

before = len(data_rating)
data_rating = data_rating[data_rating['rating'] != -1]
after = len(data_rating)
print(f"{before - after} baris dengan rating -1 telah dihapus.")
print('Jumlah Seluruh rating: ', len(data_rating.rating.unique()))
print('Nilai Rating: ', data_rating.rating.unique())
print('Jumlah Seluruh Data: ', after)

"""Pada dataset rating.csv, terdapat sebanyak 1.476.596 baris data dengan nilai rating -1 yang menandakan bahwa pengguna belum memberikan penilaian terhadap anime dihapus agar model hanya dilatih pada data yang benar-benar merepresantikan preferensi pengguna

## Randomisasi Dataset
"""

# Mengacak dataset
data_rating = data_rating.sample(frac=1, random_state=42)
data_rating.sample(5)

"""##Data_Splitting"""

# Membuat variabel x untuk mencocokkan data user dan anime menjadi satu value
x = data_rating[['user', 'anime']].values

# Membuat variabel y untuk membuat rating dari hasil
y = data_rating['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * data_rating.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""Membagi dataset menjadi data pelatihan dan data validasi dengan proporsi 80:20"""

data = preparation
data.head(10)

"""## Content Based Featur Engineering dengan TF-IDF"""

tfidf = TfidfVectorizer()
tfidf.fit(data['genre'])
tfidf.get_feature_names_out()

"""Kode ini digunakan untuk mengekstrak daftar kata unik (fitur) dari kolom genre menggunakan teknik TF-IDF tanpa langsung melakukan transformasi ke matriks."""

tfidf_matrix = tfidf.fit_transform(data['genre'])
tfidf_matrix.shape

"""Berdasarkan kode diatas diketahui bahwa, panjang data genre sejumlah 9894 data dengan 47 data unik"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf.get_feature_names_out(),
    index=data.name
).sample(20, axis=1).sample(10, axis=0)

"""##  Perhitungan Cosine Similarity"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama resto
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['name'], columns=data['name'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap resto
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""## Mendapatkan Rekomendasi

### Content Based Filtering
"""

def anime_recommendations(nama_anime, similarity_data=cosine_sim_df, items=data[['name', 'genre']], k=5):
    index = similarity_data.loc[:,nama_anime].to_numpy().argpartition(
        range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(nama_anime, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

data.sample(20)

"""Dataframe diatas berisi data anime yang dapat digunakan untuk melakukan testing rekomendasi anime"""

anime_recommendations('Ohisama to Kaeru')

"""Dapat diketahui bahwa anime Ohisama to Kaeru menghasilkan 5 rekomendasi anime yang lain dengan genre yang sama

# Collaborative Filtering
"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_anime, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_anime = num_anime
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.anime_embedding = layers.Embedding( # layer embeddings resto
        num_anime,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.anime_bias = layers.Embedding(num_anime, 1) # layer embedding resto bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    anime_vector = self.anime_embedding(inputs[:, 1]) # memanggil layer embedding 3
    anime_bias = self.anime_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_anime = tf.tensordot(user_vector, anime_vector, 2)

    x = dot_user_anime + user_bias + anime_bias

    return tf.nn.sigmoid(x) # activation sigmoid

model = RecommenderNet(num_users, num_anime, 50) # inisialisasi model

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 1,
    validation_data = (x_val, y_val)
)

data_rating.head()

anime_df = preparation
data = pd.read_csv('rating.csv')

# Mengambil sample user
user_id = data.user_id.sample(1).iloc[0]
anime_watched_by_user = data[data.user_id == user_id]

# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html
anime_not_watched = anime_df[~anime_df['id'].isin(anime_watched_by_user.anime_id.values)]['id']
anime_not_watched = list(
    set(anime_not_watched)
    .intersection(set(anime_to_anime_encoded.keys()))
)

anime_not_watched = [[anime_to_anime_encoded.get(x)] for x in anime_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_anime_array = np.hstack(
    ([[user_encoder]] * len(anime_not_watched), anime_not_watched)
)

ratings = model.predict(user_anime_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_anime_ids = [
    anime_encoded_to_anime.get(anime_not_watched[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Anime with high ratings from user')
print('----' * 8)

top_anime_user = (
    anime_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .anime_id.values
)

anime_df_rows = anime_df[anime_df['id'].isin(top_anime_user)]
for row in anime_df_rows.itertuples():
    print(row.name, ':', row.genre)

print('----' * 8)
print('Top 10 anime recommendation')
print('----' * 8)

recommended_anime = anime_df[anime_df['id'].isin(recommended_anime_ids)]
for row in recommended_anime.itertuples():
    print(row.name, ':', row.genre)